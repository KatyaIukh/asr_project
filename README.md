# Fine-tuning Whisper with LoRA for Upper Sorbian Speech Recognition

## О проекте

Данная работа посвящена дообучению модели Whisper с использованием LoRA адаптеров для автоматического распознавания речи на низкоресурсном языке. В качестве примера используется верхнелужицкий язык.

**Верхнелужицкий** – один из двух языков лужичан, славянского народа, проживающего на территории Лужицы в Германии. Данный язык представлен в последних версиях наборов Common Voice, однако аудио данные суммарно составляют всего 4 часа речи, что может быть недостаточно для полноценного дообучения. Именно поэтому данный язык был выбран как пример в работе, посвящённой низкоресурсным языкам.

## Подходы к дообучению

Рассмотрено два подхода к дообучению модели Whisper-small для распознавания верхнелужицкого языка:

### 1. Классический подход
Дообучение монолингвального LoRA адаптера непосредственно на целевом языке (верхнелужицком).

### 2. Двуэтапный подход с использованием родственного языка
В данном подходе мы используем данные на близком к целевому, но более высокоресурсном языке (чешский).

**Этапы двуэтапного подхода:**
- На первом этапе обучается монолингвальный адаптер на чешских данных
- С использованием функции `merge_and_unload` библиотеки PeftModel веса адаптера объединяются с исходной моделью Whisper
- Создаётся новая модель, адаптированная под понимание западнославянских языков
- На втором этапе используется стандартное обучение LoRA адаптера на моноязычных данных верхнелужицкого языка
  
<img width="1903" height="962" alt="Снимок экрана (3082)" src="https://github.com/user-attachments/assets/ec2a9ebf-7a9d-4e0b-90fd-90294d86ec93" />


## Данные для обучения

- **Чешский язык**: ~9.43 часов аудио данных
- **Верхнелужицкий язык**: ~4 часов аудио данных
- Формат данных: JSON файлы с путями к MP3 файлам и соответствующими транскрипциями

## Параметры обучения

| Параметр | Чешский адаптер | Верхнелужицкий адаптер |
|----------|------------------|------------------------|
| **Batch size** | 8 | 8 |
| **Learning rate** | 1e-3 | 1e-3 |
| **Эпохи** | 3 | 3 |
| **LoRA rank (r)** | 32 | 32 |
| **LoRA alpha** | 64 | 64 |

## Результаты

Оценка качества модели с добавлением LoRa адаптера на верхнелужицком языке:
<img width="2087" height="1407" alt="image" src="https://github.com/user-attachments/assets/f87dc576-798f-4704-967f-54eccd06a488" />

Видно, что высокий средний WER обусловлен редкими выбросами, в целом модель демонстрирует возможность распознавать верхнелужицкую речь, что связано с наличием славянских языков в данных для обучения оригинального whisper, однако качество распознования невысоко

Оценка качества модели, предобученной на чешском языке до обучение на верхнелужицком:
<img width="2060" height="1407" alt="wer_distribution" src="https://github.com/user-attachments/assets/dc716038-ec2d-4e2f-931c-81c1c59e0fa2" />

Как видно из гистограммы, качество распознования речи существенно улучшилось
Стоит отметить, что обычно при дообучении ASR моделей используется в разы больше аудио данных, чем 10 часов аудио, сколько использовалось для предварительного обучения адаптера на чешском языке в данной работе, так что повышение качества даже при небольшом количестве данных для обучения показывает преимущества подхода к высокоресурсным "языком-посредником" при дообучении моделей распознования речи на низкоресурсные языки

## Структура проекта
