# Fine-tuning Whisper with LoRA for Upper Sorbian Speech Recognition

## О проекте

Данная работа посвящена дообучению модели Whisper с использованием LoRA адаптеров для автоматического распознавания речи на низкоресурсном языке. В качестве примера используется верхнелужицкий язык.

**Верхнелужицкий** – один из двух языков лужичан, славянского народа, проживающего на территории Лужицы в Германии. Данный язык представлен в последних версиях наборов Common Voice, однако аудио данные суммарно составляют всего 4 часа речи, что может быть недостаточно для полноценного дообучения. Именно поэтому данный язык был выбран как пример в работе, посвящённой низкоресурсным языкам.

## Подходы к дообучению

Рассмотрено два подхода к дообучению модели Whisper-small для распознавания верхнелужицкого языка:

### 1. Классический подход
Дообучение монолингвального LoRA адаптера непосредственно на целевом языке (верхнелужицком).

### 2. Двуэтапный подход с использованием родственного языка
В данном подходе мы используем данные на близком к целевому, но более высокоресурсном языке (чешский).

**Этапы двуэтапного подхода:**
- На первом этапе обучается монолингвальный адаптер на чешских данных
- С использованием функции `merge_and_unload` библиотеки PeftModel веса адаптера объединяются с исходной моделью Whisper
- Создаётся новая модель, адаптированная под понимание западнославянских языков
- На втором этапе используется стандартное обучение LoRA адаптера на моноязычных данных верхнелужицкого языка
  
<img width="624" height="339" alt="image" src="https://github.com/user-attachments/assets/2df23c84-2295-4fd3-a838-82950f05ab8d" />

## Данные для обучения

- **Чешский язык**: ~9.43 часов аудио данных
- **Верхнелужицкий язык**: ~4 часов аудио данных
- Формат данных: JSON файлы с путями к MP3 файлам и соответствующими транскрипциями

## Параметры обучения

| Параметр | Чешский адаптер | Верхнелужицкий адаптер |
|----------|------------------|------------------------|
| **Batch size** | 8 | 8 |
| **Learning rate** | 1e-3 | 1e-3 |
| **Эпохи** | 3 | 3 |
| **LoRA rank (r)** | 32 | 32 |
| **LoRA alpha** | 64 | 64 |
| **Target modules** | q_proj, v_proj | q_proj, v_proj |

## Результаты

*Результаты будут добавлены после завершения экспериментов*

## Структура проекта
